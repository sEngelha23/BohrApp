{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically reload external modules (see https://ipython.org/ipython-doc/3/config/extensions/autoreload.html for more information).\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Set up system path to include our own \"mldog\" python package.\n",
    "import sys\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages / Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters\n",
    "from tsfresh.feature_extraction import MinimalFCParameters\n",
    "from tsfresh.feature_extraction import EfficientFCParameters\n",
    "from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "\n",
    "\n",
    "\n",
    "# our own drill util library\n",
    "import src.mldog.util.drill as dog\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly_express as px\n",
    "\n",
    "# Everything around pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pickle\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fragen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmeasurements = pd.read_csv('./data/Daten_Team_9/measurements.csv')\n",
    "dfmeasurements.head()\n",
    "\n",
    "\n",
    "# Startpoint\n",
    "startpoint = pd.read_csv('./data/Daten_Team_9/2024_10_23_09_58_52_96000Hz.csv')\n",
    "\n",
    "# Dataframe fürs Training\n",
    "startpoint['ID'] = 0\n",
    "df = extract_features(startpoint, column_id= 'ID', default_fc_parameters= MinimalFCParameters(), n_jobs=0)\n",
    "df['time'] = df.shape[0] / 96000\n",
    "\n",
    "\n",
    "# Listgeneration for Traindataframe\n",
    "for datafr in dfmeasurements['dataFile'][1:]:\n",
    "\n",
    "    # Momentaner Dataframe\n",
    "    tempdf = pd.read_csv(f'data\\Daten_Team_9/{datafr}') # Pfad variiert je nach Pc -> damit funktioniert anpassen\n",
    "\n",
    "    # Per hand features\n",
    "    time = tempdf.shape[0] / 96000\n",
    "\n",
    "    #hinzufügen der ID\n",
    "    tempdf['ID'] = 0\n",
    "    \n",
    "\n",
    "\n",
    "    features = extract_features(tempdf, column_id= 'ID', default_fc_parameters= MinimalFCParameters(), n_jobs=0) # MinimalFCParameters() # Minimal\n",
    "    features['time'] = time\n",
    "\n",
    "    df = pd.concat([df, features])\n",
    "\n",
    "    # if datafr == breakpoint1:\n",
    "    #     break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexanpassung für feature selection\n",
    "df.index = range(0, df.shape[0])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train und Testdata Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train und Testdata generierung\n",
    "X_train = df #[:70]\n",
    "y_train = dfmeasurements['material']#[:70]\n",
    "\n",
    "# X_test = dfTrain[70:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model & export "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# fit classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# build pickle file\n",
    "# with open('pipelinecdfFulldata.pkl','wb') as modelFile:\n",
    "#     pickle.dump(clf, modelFile)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tsfresh Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# Test dataframe \n",
    "########################################\n",
    "\n",
    "testtrans = pd.read_csv('./data/Daten_Team_9/2024_10_23_09_58_52_96000Hz.csv') # Pfade anpassen\n",
    "testts = pd.read_csv('./data/Daten_Team_9/2024_10_23_09_58_52_96000Hz.csv') # Pfade anpassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testts['ID'] = 0\n",
    "testts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter\n",
    "minimal = MinimalFCParameters()\n",
    "# efficient = EfficientFCParameters()\n",
    "\n",
    "custom_params = {\n",
    "    \"mean\": None,\n",
    "    #\"standard_deviation\": None,\n",
    "    #\"maximum\": None,\n",
    "    #\"minimum\": None,\n",
    "    #\"sum_values\": None\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction \n",
    "\n",
    "featuresmin = extract_features(testts, column_id= 'ID', default_fc_parameters= minimal, n_jobs=0) # MinimalFCParameters() # Minimal\n",
    "# featureseff = extract_features(testts, column_id= 'ID', default_fc_parameters= efficient, n_jobs=0) # MinimalFCParameters() # Efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "\n",
    "calculate_relevance_table(df, dfmeasurements['material'], n_jobs= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "\n",
    "# y_pred = []\n",
    "\n",
    "# for toPredict in X_test:\n",
    "\n",
    "#     y_pred += [model.predict(toPredict)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Accuracy score\n",
    "# accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verbesserung\n",
    "- Crossvalidation\n",
    "- Hyperparameter\n",
    "- Andere Klassifikatoren\n",
    "- Feature Engineering"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aki",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
